{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-blob in /usr/local/python/3.10.13/lib/python3.10/site-packages (12.19.1)\n",
      "Requirement already satisfied: azure-identity in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.15.0)\n",
      "Requirement already satisfied: azure-ai-documentintelligence in /usr/local/python/3.10.13/lib/python3.10/site-packages (1.0.0b2)\n",
      "Collecting azure.ai.formrecognizer\n",
      "  Downloading azure_ai_formrecognizer-3.3.2-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from azure-storage-blob) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from azure-storage-blob) (42.0.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-storage-blob) (4.10.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from azure-storage-blob) (0.6.1)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from azure-identity) (1.27.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from azure-identity) (1.1.0)\n",
      "Collecting msrest>=0.6.21 (from azure.ai.formrecognizer)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-common~=1.1 (from azure.ai.formrecognizer)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/codespace/.local/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/codespace/.local/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity) (2.8.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (23.2)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from msrest>=0.6.21->azure.ai.formrecognizer) (2024.2.2)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure.ai.formrecognizer)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-blob) (2.0.7)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure.ai.formrecognizer)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading azure_ai_formrecognizer-3.3.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.1/300.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: azure-common, oauthlib, requests-oauthlib, msrest, azure.ai.formrecognizer\n",
      "Successfully installed azure-common-1.1.28 azure.ai.formrecognizer-3.3.2 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-storage-blob azure-identity azure-ai-documentintelligence azure.ai.formrecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "import os\n",
    "\n",
    "output_directory = \"./txt/\"\n",
    "\n",
    "def doing(file_name):\n",
    "\n",
    "    # Azure Document Intelligence  서비스의 엔드포인트와 키, 모델 이름\n",
    "    form_recognizer_endpoint = \"https://globalaibootcamp-s1-01.cognitiveservices.azure.com/\" # #메모했던 내용으로 수정\n",
    "    form_recognizer_key = \"75b7320edf304e52981f453cfda924ad\" # #메모했던 내용으로 수정\n",
    "    model_id = \"first_model\" #메모했던 내용으로 수정\n",
    "\n",
    "    # Azure Blob Storage 계정 정보\n",
    "    blob_account_name = \"gabs101\" #메모했던 내용으로 수정\n",
    "    blob_account_key = \"BP3TFJ+rMuxxCq/zDutEjqVCuuAfjijzEaUEe07wwsofI2XTpZ/+w0hRxMEV2wQYYIlCDvV7Ubez+AStoDXWeA==\" # #메모했던 내용으로 수정\n",
    "\n",
    "    # Blob Storage 클라이언트 생성\n",
    "    blob_service_client = BlobServiceClient(\n",
    "        account_url=f\"https://{blob_account_name}.blob.core.windows.net\",\n",
    "        credential=blob_account_key\n",
    "    )\n",
    "\n",
    "    # Blob의 일반 링크\n",
    "    # #blob에서 예제 1의 url : https://계정이름.blob.core.windows.net/gabs101/예제1.pdf 이렇게 되어 있는데 https://계정이름.blob.core.windows.net/gabs101/ 이걸 붙여넣기\n",
    "    blob_url = f'https://gabs101.blob.core.windows.net/gabs101/{file_name}' # #메모했던 예제1  URL 일부 내용으로 수정. /{file_name}은 그대로 둬 주세요\n",
    "\n",
    "    # Blob 다운로드\n",
    "    blob_client = BlobClient.from_blob_url(blob_url, credential=blob_account_key)\n",
    "    blob_data = blob_client.download_blob().readall()\n",
    "\n",
    "    # Document Analysis 클라이언트 생성\n",
    "    document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=form_recognizer_endpoint, credential=AzureKeyCredential(form_recognizer_key)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Make sure your document's type is included in the list of document types the custom model can analyze\n",
    "    poller = document_analysis_client.begin_analyze_document(model_id, blob_data)\n",
    "    result = poller.result()\n",
    "\n",
    "    txt_file_name = os.path.join(output_directory, f\"{os.path.splitext(file_name)[0]}.txt\")\n",
    "\n",
    "    for document in result.documents:\n",
    "        with open(txt_file_name, \"w\") as file:\n",
    "            for name, field in document.fields.items():\n",
    "                field_value = field.value if field.value else field.content\n",
    "                print(\"{}:'{}'\".format(name, field_value))\n",
    "                file.write(f\"{name}: '{field_value}'\\n\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reason:'걍 참 가 했 음'\n",
      "learnt:'Thank u so much 여 러 분'\n",
      "information:'{'name': DocumentField(value_type=dictionary, value={'ROW1': DocumentField(value_type=string, value='개 구 리', content=개구리, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=1.7, y=5.905), Point(x=2.31, y=5.905), Point(x=2.31, y=6.155), Point(x=1.7, y=6.155)])], spans=[DocumentSpan(offset=136, length=3)], confidence=None)}, content=None, bounding_regions=[], spans=[], confidence=None), 'birth': DocumentField(value_type=dictionary, value={'ROW1': DocumentField(value_type=string, value='2023/03/23', content=2023/03/23, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=3.51, y=5.92), Point(x=4.655, y=5.92), Point(x=4.655, y=6.17), Point(x=3.51, y=6.17)])], spans=[DocumentSpan(offset=140, length=10)], confidence=None)}, content=None, bounding_regions=[], spans=[], confidence=None), 'phone': DocumentField(value_type=dictionary, value={'ROW1': DocumentField(value_type=string, value='010-2555-8999', content=010-2555-8999, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=5.425, y=5.915), Point(x=6.94, y=5.915), Point(x=6.94, y=6.155), Point(x=5.425, y=6.155)])], spans=[DocumentSpan(offset=151, length=13)], confidence=None)}, content=None, bounding_regions=[], spans=[], confidence=None)}'\n",
      "satis_survey:'[DocumentField(value_type=dictionary, value={'satis': DocumentField(value_type=string, value='V', content=V, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=4.515, y=8.105), Point(x=4.645, y=8.105), Point(x=4.645, y=8.34), Point(x=4.515, y=8.34)])], spans=[DocumentSpan(offset=218, length=1)], confidence=None), 'dissatis': DocumentField(value_type=string, value=None, content=None, bounding_regions=[], spans=[], confidence=None)}, content=None, bounding_regions=[], spans=[], confidence=None), DocumentField(value_type=dictionary, value={'satis': DocumentField(value_type=string, value='V', content=V, bounding_regions=[BoundingRegion(page_number=1, polygon=[Point(x=4.525, y=8.69), Point(x=4.655, y=8.69), Point(x=4.655, y=8.925), Point(x=4.525, y=8.925)])], spans=[DocumentSpan(offset=234, length=1)], confidence=None), 'dissatis': DocumentField(value_type=string, value=None, content=None, bounding_regions=[], spans=[], confidence=None)}, content=None, bounding_regions=[], spans=[], confidence=None)]'\n"
     ]
    }
   ],
   "source": [
    "doing(\"예제1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        memo = file.read()\n",
    "\n",
    "\n",
    "        reason_section = re.search(r\"reason: '(.*?)'\", memo)\n",
    "        learnt_section = re.search(r\"learnt: '(.*?)'\", memo)\n",
    "        information_section_match = re.search(r\"information: '{(.+?)}'\", memo) \n",
    "        satis_survey_section = re.search(r\"satis_survey:\\s*'\\[(.*?)\\]'\", memo) \n",
    "\n",
    "        information_data = {}\n",
    "\n",
    "\n",
    "        if information_section_match:\n",
    "                            information_text = information_section_match.group(1)  # Extract key\n",
    "                            print(\"txt : \"+str(information_section_match))\n",
    "\n",
    "                            # Improved regex for nested dictionaries\n",
    "                            info_pattern = r\"'(\\w+)': DocumentField\\(value_type=dictionary, value={'ROW1': DocumentField\\(value_type=string, value='(.*?)', content=(.*?),\"\n",
    "\n",
    "                            \n",
    "\n",
    "                            # Use information_text directly in finditer\n",
    "                            for match in re.finditer(info_pattern, information_text):\n",
    "                                key = match.group(1)\n",
    "            \n",
    "                                content = match.group(3).strip(\",\")\n",
    "                                information_data[key] = content\n",
    "                \n",
    "\n",
    "\n",
    "        satis_survey_data = []\n",
    "        if satis_survey_section:\n",
    "            satis_survey_text = satis_survey_section.group(1)\n",
    "            for match in re.finditer(r\"\\{.*?\\}\", satis_survey_text):\n",
    "                value = match.group()\n",
    "                satis_match = re.search(r\"'satis':\\s*DocumentField.*?value='(.*?)'\", value)\n",
    "                dissatis_match = re.search(r\"'dissatis':\\s*DocumentField.*?value='(.*?)'\", value)\n",
    "                satis = satis_match.group(1).strip() if satis_match else None\n",
    "                dissatis = dissatis_match.group(1).strip() if dissatis_match else None\n",
    "                satis_survey_data.append({'satis': satis, 'dissatis': dissatis})\n",
    "\n",
    "    return {\n",
    "        'reason': reason_section.group(1) if reason_section else None,\n",
    "        'learnt': learnt_section.group(1) if learnt_section else None,\n",
    "        'information': information_data,\n",
    "        'satis_survey': satis_survey_data\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in test_files:\\n    doing(str(i)+\".pdf\")'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files=[\"예제1\", \"예제2\"]\n",
    "'''\n",
    "for i in test_files:\n",
    "    doing(str(i)+\".pdf\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<re.Match object; span=(1093, 2349), match=\"information: '{'name': DocumentField(value_type=d>\n",
      "txt : <re.Match object; span=(1093, 2349), match=\"information: '{'name': DocumentField(value_type=d>\n",
      "{'reason': '걍 참 가 했 음', 'learnt': 'Thank u so much 여 러 분', 'information': {'name': '개구리', 'birth': '2023/03/23', 'phone': '010-2555-8999'}, 'satis_survey': [{'satis': 'V', 'dissatis': None}, {'satis': 'V', 'dissatis': None}]}\n",
      "0\n",
      "<re.Match object; span=(80, 1338), match=\"information: '{'name': DocumentField(value_type=d>\n",
      "txt : <re.Match object; span=(80, 1338), match=\"information: '{'name': DocumentField(value_type=d>\n",
      "{'reason': '인 공 지 능 에 대 해 서 배 우 고 싶 어 서 요', 'learnt': '인 공 지 능 을 앞 으 로 만 들 수 있 는 능 력', 'information': {'name': '옥토캣', 'birth': '2008/02/08', 'phone': '010-8888-8888'}, 'satis_survey': [{'satis': '√', 'dissatis': None}, {'satis': '√', 'dissatis': None}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for i in test_files:\n",
    "    txt_file_path = \"./txt/\"+str(i)+\".txt\"\n",
    "\n",
    "    # 함수 호출 및 결과 출력\n",
    "    parsed_data = parse_file(txt_file_path)\n",
    "    print(parsed_data)\n",
    "    \n",
    "    # 딕셔너리를 JSON 형식의 문자열로 변환\n",
    "    json_data = json.dumps(parsed_data, ensure_ascii=False)\n",
    "\n",
    "    # 파일을 쓰기 모드로 열기 (파일이 없으면 생성됨)\n",
    "    with open(txt_file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        # JSON 형식의 문자열을 파일에 쓰기\n",
    "        file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# 경로 설정\n",
    "directory = './txt/'\n",
    "output_file = 'output.csv'\n",
    "\n",
    "# CSV 파일에 저장할 헤더\n",
    "csv_headers = ['reason', 'learnt', 'name', 'birth', 'phone', 'satis_survey1', 'satis_survey2']\n",
    "\n",
    "# CSV 파일 열기 및 헤더 쓰기\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # 디렉토리 내의 모든 파일에 대해 반복\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            # 파일 열기 및 JSON 데이터 로드\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                row = {}\n",
    "                # 필요한 데이터 추출\n",
    "                row['reason'] = data.get('reason', '')\n",
    "                row['learnt'] = data.get('learnt', '')\n",
    "                row['name'] = data['information']['name']\n",
    "                row['birth'] = data['information']['birth']\n",
    "                row['phone'] = data['information']['phone']\n",
    "                # satis_survey가 null이 아닌 경우에만 값을 할당\n",
    "                if data['satis_survey'][0]['satis'] is not None:\n",
    "                    row['satis_survey1'] = data['satis_survey'][0]['satis']\n",
    "                else:\n",
    "                    row['satis_survey1'] = ''\n",
    "                if data['satis_survey'][1]['satis'] is not None:\n",
    "                    row['satis_survey2'] = data['satis_survey'][1]['satis']\n",
    "                else:\n",
    "                    row['satis_survey2'] = ''\n",
    "                # CSV 파일에 데이터 쓰기\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일의 인코딩: utf-8\n"
     ]
    }
   ],
   "source": [
    "import chardet\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return chardet.detect(rawdata)['encoding']\n",
    "\n",
    "file_path = '/workspaces/azureappdeploy/txt/예제2.txt'  # 파일 경로를 적절하게 변경하세요\n",
    "encoding = detect_encoding(file_path)\n",
    "print(\"파일의 인코딩:\", encoding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
